<!-- 61565911-3314-40cb-86a0-f7f30d68a79a 7ae9314b-1f47-4a07-910a-b371ba4f87f0 -->
# Horadric Cube Python Simulation Plan

### 1. Data loading and core models

- Define Python data classes for `Item`, `Recipe`, `Rarity`, and `ItemType`, mirroring Godot enums and CSV schemas (`data/item_properties.csv`, `data/recipe_properties.csv`).
- Implement CSV loaders that parse those two files into in-memory dictionaries/lists keyed by IDs, matching `ItemProperties` / `RecipeProperties` logic (including mapping strings like `"regular"`, `"oil"`, `"consumable"`, rarity strings, and numeric fields).
- Add a small constants section for commonly referenced items, e.g. `ENCHANTED_MINING_PICK = 8`, and leave a clear area for users to add their own IDs.

### 2. Recreate deterministic recipe logic

- Re-implement the Horadric cube helper logic in Python in a modular way:
- Ingredient rarity validation and selection based on `rarity_change` and the rarity sweep used by `get_item_list_for_autofill_for_rarity`.
- Ingredient type/count validation using `permanent_count` vs `usable_count`, mapping to `ItemType.REGULAR` vs `OIL`/`CONSUMABLE`.
- Average level computation over permanent ingredients only, using `required_wave_level` from item properties plus the aggregate level contribution of unspecified items.
- Provide a function that, given a recipe ID and a combination of:
- explicit ingredient item IDs (with levels from properties), and
- an aggregate `(count, sum_levels)` of additional permanent ingredients and/or usables,
returns a fully specified effective average item level and filtered ingredient ID list (explicit IDs only) for downstream calculations.

### 3. Item pool reconstruction (drop tables)

- Implement pure functions that mirror `ItemDropCalc.get_item_list_bounded` and `get_oil_and_consumables_list`:
- Build candidate permanent item pools by rarity and required-wave-level bounds.
- Build candidate usable item pools (oils + consumables) by rarity.
- Expose functions to compute the candidate pools used by a recipe result given: recipe, result rarity, and effective level bounds.

### 4. Probabilistic decision model

- Design a small hierarchy of Python classes to represent random decision points:
- A `DecisionNode` abstraction that can operate in two modes:
- "roll" mode: sample a concrete outcome using Python RNG.
- "enumerate" mode: return a list of `(probability, outcome)` pairs.
- Two key node types:
- `LuckNode` for the random bonus modifier with weights `{ -9:20, 0:50, 7:20, 18:10 }`.
- `ItemChoiceNode` for uniform choices among candidate item IDs.
- Allow configuration per node type (e.g. via an options object or flags) to either roll or enumerate:
- e.g. `DecisionOptions(luck_mode="enumerate", item_choice_mode="enumerate")`.
- Implement composition utilities that build a decision tree for a given recipe: luck node → level range → item pool node(s) → resulting item IDs.

### 5. Distribution collapsing utilities

- Implement functions to traverse a decision tree in enumerate mode and produce a flat probability distribution over item IDs:
- Multiply probabilities along each path from root to leaf.
- Sum probabilities for paths that end in the same item ID to get the final marginal distribution.
- Provide a convenience API like `get_item_distribution(recipe_id, explicit_items, aggregate_levels, options)` that returns `{item_id: probability}`.

### 6. Result generation API (single roll vs full distribution)

- Implement a user-facing function to **roll a concrete result**:
- `roll_recipe(recipe_id, explicit_items, aggregate_levels, rng=None)` that applies the same logic as Godot but using Python’s RNG, returning item ID list.
- Implement a user-facing function to **compute distributions**:
- `analyze_recipe_distribution(recipe_id, explicit_items, aggregate_levels, options)` returning a structured result with:
- luck distribution (if requested),
- per-item full probability distribution,
- any intermediate pool sizes useful for debugging.

### 7. Analysis over average levels for target item

- Implement an analysis function:
- `find_best_avg_level_for_item(target_item_id, recipe_id, level_range, explicit_items=None, aggregate_count=None)`.
- For each candidate effective average level in the given range:
- Construct a compatible `(count, sum_levels)` aggregate that yields that average for permanent ingredients (respecting recipe counts but without caring about exact composition beyond average).
- Build the distribution over result items using enumeration.
- Record the probability mass assigned to `target_item_id`.
- Return:
- the level with maximum probability for the target item,
- the full mapping `avg_level -> probability` for inspection.

### 8. CLI / example usage and documentation

- Add a simple CLI or example `main()` that demonstrates:
- Loading CSVs.
- Computing and printing the distribution for a recipe (e.g. `Reassemble`) at a given average level.
- Running `find_best_avg_level_for_item` for known items like `ENCHANTED_MINING_PICK`.
- Document how to extend named constants for items and how to adjust ranges/options for analysis.

### 9. Validation strategy

- Write a few small, fast tests comparing:
- Python candidate pools vs Godot `ItemDropCalc` pools for selected rarities and level ranges.
- Example Horadric cube rolls vs a small number of observed runs from the game (spot checks, not exact RNG alignment).
- Use these to iteratively refine edge cases (e.g. empty pools, high-level bounds, PRECIPITATE special case).

### To-dos

- [ ] Implement Python data models and CSV loaders for items and recipes, plus named item ID constants
- [ ] Rebuild Horadric cube ingredient rarity, type/count checks, and average-level computation in Python
- [ ] Mirror ItemDropCalc pools for permanent and usable items as pure Python functions
- [ ] Implement decision node abstractions (luck and item choice) with roll/enumerate modes and tree composition
- [ ] Add utilities to collapse decision trees to item distributions and user-facing roll/analysis APIs
- [ ] Implement and expose the best-average-level-for-item analysis over a specified level range
- [ ] Create small CLI/example usage and basic tests comparing against Godot behavior